\documentclass[letterpaper,11pt]{article}

\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage[usenames,dvipsnames]{color}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\input{glyphtounicode}

% ---------- PAGE SETUP ----------
\pagestyle{fancy}
\fancyhf{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
% slightly widen right margin to avoid any overflow
\usepackage[top=0.28in, bottom=0.32in, left=0.28in, right=0.35in]{geometry}

\urlstyle{same}
\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

% ---------- SECTION FORMATTING ----------
\titleformat{\section}{
  \scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-2pt}]
\titlespacing*{\section}{0pt}{6pt plus 1pt minus 1pt}{3pt plus 1pt minus 1pt}

\pdfgentounicode=1
\setlength{\parindent}{0pt}
\renewcommand{\baselinestretch}{0.93}

% ---------- CUSTOM COMMANDS (updated to use wrap-capable columns) ----------
% resumeSubheading: left column is p{0.65\textwidth} so long institution or role text wraps
\newcommand{\resumeItem}[1]{\item\small{{#1 \vspace{-2pt}}}}

\newcommand{\resumeSubheading}[4]{\vspace{0pt}\item
  \begin{tabular*}{0.965\textwidth}[t]{p{0.65\textwidth}@{\extracolsep{\fill}}r}
    \textbf{#1} & \textit{\small #2} \\
    \textit{\small #3} & \textit{\small #4} \\
  \end{tabular*}\vspace{3pt}}  % slightly increased vspace to aid readability

% resumeEduheading similarly wraps
\newcommand{\resumeEduheading}[4]{\vspace{0pt}\item
  \begin{tabular*}{0.93\textwidth}[t]{p{0.8\textwidth}@{\extracolsep{\fill}}r}
    \textbf{#1} & \textit{\small #2} \\
    \textit{\small #3} & \textit{\small #4} \\
  \end{tabular*}\vspace{3pt}}

\newcommand{\resumeProjectHeading}[2]{\item
  \begin{tabular*}{0.965\textwidth}{p{0.78\textwidth}@{\extracolsep{\fill}}r}
    \small#1 & #2 \\
  \end{tabular*}\vspace{-4pt}}

\newcommand{\resumeSubItem}[1]{\resumeItem{#1}\vspace{-3pt}}
\renewcommand\labelitemii{$\vcenter{\hbox{\tiny$\bullet$}}$}
\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0.14in, label={}, itemsep=1pt]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}[leftmargin=0.14in, itemsep=1pt]}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-3pt}}

% ---------- DOCUMENT ----------
\begin{document}

\begin{center}
  \textbf{\Huge \scshape Soorej Santhoshkumar Nair} \\ \vspace{1pt}
  \small +1(303)-243-2932 $|$ soorej.s.nair@gmail.com $|$ linkedin.com/in/soorej-s-nair-73559470 $|$ github.com/Soorej30
\end{center}
\vspace{-12pt}

\section{Summary}
\small{
  Data Scientist with 4+ years of experience developing \textbf{deep learning and computer vision models} for real-world applications. Skilled in \textbf{Python, C++, and PyTorch} with strong expertise in \textbf{image enhancement, restoration, and generative modeling}. Experienced in building \textbf{diffusion-based and transformer architectures} for vision-language tasks, and deploying them at scale using \textbf{AWS, GCP, and Docker}. Passionate about advancing \textbf{AI-driven imaging systems} and applying generative AI to improve camera performance and user experience.
}

\section{Experience}
\resumeSubHeadingListStart

  \resumeSubheading
    {Senior Data Scientist}{Sep 2024 -- Jul 2025}
    {XPO Logistics}{Pune, India}
    \resumeItemListStart
      \resumeItem{Developed a Random Forest churn prediction model that achieved 90\% precision in the top decile, preventing over \$240M in potential revenue loss.}
      \resumeItem{Designed an end-to-end LLM pipeline integrating CV, NLP, and OCR workflows for automated invoice extraction and classification using Google Gemini, GCP, and Vertex AI.}
      \resumeItem{Partnered with McKinsey to develop a Machine Learning-based logistics simulation model (Cerebro) implemented across 300+ centers, improving freight handling efficiency by 54\%.}
      \resumeItem{Built decision tree models to detect fraudulent claims using Vertex AI and SQL queries on structured datasets, generating \$15K monthly.}
    \resumeItemListEnd

  \resumeSubheading
    {Data Scientist}{Jul 2022 -- Aug 2024}
    {XPO Logistics}{Pune, India}
    \resumeItemListStart
      \resumeItem{Developed ARIMA-based time series forecasting models in R, Python, and BQML to predict employee attrition, applying data-driven insights through stakeholder reports.}
      \resumeItem{Applied expertise with object-oriented programming languages (Python) and ML libraries (TensorFlow, PyTorch) to design and implement scalable Machine Learning solutions.}
      \resumeItem{Designed computer vision audit platforms using GCP, Pub/Sub, SQL, and Vertex AI Pipelines, processing 80K+ documents daily, enhancing data quality metrics and saving 10K+ manual hours annually.}
    \resumeItemListEnd

  \resumeSubheading
    {Associate Data Scientist}{Jul 2021 -- Jun 2022}
    {XPO Logistics}{Hyderabad, India}
    \resumeItemListStart
      \resumeItem{Developed CNN-based models for accessorial optimization and trailer image analysis, analyzing statistical trends and performance metrics to improve product reliability and generate \$1.3M in incremental revenue.}
      \resumeItem{Developed ARIMA-based time series forecasting models in R, Python, and BQML to predict employee attrition. Communicated insights through data visualization, storytelling, and stakeholder reports for data-driven workforce planning.}
    \resumeItemListEnd

\resumeSubHeadingListEnd

\section{Projects}
\resumeSubHeadingListStart

  \resumeProjectHeading
    {\textbf{Transformer based Hindi poetry generator} $|$ \emph{Python, PyTorch, TensorFlow, NLTK, Transformers, Keras, SQL, R}}{}
    \resumeItemListStart
      \resumeItem{Built a custom Transformer-based generative model leveraging natural language processing (NLP) and statistical text analysis. Applied data wrangling, feature engineering, and model evaluation metrics to assess creativity and linguistic coherence.}
    \resumeItemListEnd

  \resumeProjectHeading
    {\textbf{Implementation of Sparsity Invariant CNNs} $|$ \emph{OpenCV, Scikit-learn, MATLAB, PyTorch, Pandas}}{}
    \resumeItemListStart
      \resumeItem{Implemented sparse convolutional neural networks (SCNNs) for LiDAR data in Python and MATLAB, applying statistical validation, data visualization, and quantitative performance measurement to compare against traditional CNNs.}
    \resumeItemListEnd


\resumeSubHeadingListEnd

\section{Education}
\resumeSubHeadingListStart
  \resumeEduheading
    {University of Colorado, Boulder}{Aug 2025 -- May 2027}
    {Master of Science in Data Science | GPA: 4.00 | Focus: Machine Learning, Computer Vision, Generative AI}{}
  \resumeEduheading
    {Birla Institute of Technology and Science, Pilani}{Aug 2017 -- May 2021}
    {Bachelor of Engineering in Computer Science| GPA: 3.10| Relevant Coursework: Machine Learning, Deep Learning, Computer Vision, Neural Networks, Cryptography}{}
\resumeSubHeadingListEnd

\section{Technical Skills}
\begin{itemize}[leftmargin=0.15in, label={}]
  \small{\item{
    \textbf{Languages}{: Python, C++, C, Rust, Java, SQL, MATLAB} \\
    \textbf{Frameworks}{: PyTorch, TensorFlow, Keras, Hugging Face, Diffusers, OpenCV, Scikit-learn} \\
    \textbf{Generative AI}{: Diffusion Models, Vision-Language Models (CLIP, BLIP, Stable Diffusion), GANs, Autoencoders} \\
    \textbf{Cloud \& Tools}{: AWS, GCP, Docker, Kubernetes, Git, MLflow, Airflow} \\
    \textbf{Core Competencies}{: Image Enhancement, Image Restoration, Generative Modeling, Multimodal Learning, Computer Vision, Deep Learning, Model Optimization}
  }}
\end{itemize}

\end{document} 